{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c348e-7a45-4dbd-80a4-050360b42e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import jieba\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    DefaultDataCollator,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import RerankingEvaluator\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.inputs.data import TokensPrompt\n",
    "from vllm.distributed.parallel_state import destroy_model_parallel\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f55906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=2025):\n",
    "    \"\"\"设置随机种子\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b58a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.json') as f:\n",
    "    ori_data = json.load(f)\n",
    "\n",
    "train_split = 0.8\n",
    "total = len(ori_data)\n",
    "train_size = int(total * train_split)\n",
    "\n",
    "indices = list(range(total))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "eval_indices = indices[train_size:]\n",
    "\n",
    "train_data = [ori_data[i] for i in train_indices]\n",
    "eval_data = [ori_data[i] for i in eval_indices]\n",
    "\n",
    "print(f\"原始数据总量: {total}\")\n",
    "print(f\"训练集大小: {len(train_data)} ({len(train_data)/total:.2%})\")\n",
    "print(f\"评估集大小: {len(eval_data)} ({len(eval_data)/total:.2%})\")\n",
    "print(f\"数据是否重叠: {any(d in train_data for d in eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d769f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = []\n",
    "target_neg_number = 3\n",
    "\n",
    "for data in tqdm(train_data):\n",
    "    relevant, un_relevant = [], []\n",
    "    all_content = []\n",
    "    document_labels = []  \n",
    "    query = data['query']\n",
    "    content_private = data['content_private']\n",
    "    content_public = data['content_public']\n",
    "    for content in content_private:\n",
    "        content_text = content['content']\n",
    "        if not content_text:\n",
    "            continue\n",
    "        all_content.append(content_text)\n",
    "        document_labels.append(not content['is_relevant'])\n",
    "        if content['is_relevant']:\n",
    "            relevant.append(content_text)\n",
    "        else:\n",
    "            un_relevant.append(content_text)\n",
    "    for content in content_public:\n",
    "        content_text = content['content']\n",
    "        if not content_text:\n",
    "            continue\n",
    "        all_content.append(content_text)\n",
    "        document_labels.append(not content['is_relevant'])\n",
    "        if content['is_relevant']:\n",
    "            relevant.append(content_text)\n",
    "        else:\n",
    "            un_relevant.append(content_text)\n",
    "    \n",
    "    tokenized_corpus = [list(jieba.cut(doc)) for doc in all_content]\n",
    "    tokenized_query = list(jieba.cut(query))\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    sorted_indices = np.argsort(bm25_scores)[::-1]\n",
    "\n",
    "    # 提取难负样本和易分负样本\n",
    "    hard_negatives = []\n",
    "    easy_negatives = []\n",
    "    for idx in sorted_indices[:10]:\n",
    "        if document_labels[idx]:\n",
    "            hard_negatives.append({\n",
    "                \"content\": all_content[idx],\n",
    "                \"bm25_score\": float(bm25_scores[idx]),\n",
    "            })\n",
    "    end_idx = max(0, len(sorted_indices) - 10)\n",
    "    for idx in sorted_indices[end_idx:]:\n",
    "        if document_labels[idx]:\n",
    "            easy_negatives.append({\n",
    "                \"content\": all_content[idx],\n",
    "                \"bm25_score\": float(bm25_scores[idx]),\n",
    "            })\n",
    "\n",
    "    for pos in relevant:\n",
    "        selected_negatives = []\n",
    "        # 情况1：难负+易分负样本总数不足，用普通负样本补充\n",
    "        if len(hard_negatives) + len(easy_negatives) < target_neg_number:\n",
    "            selected_negatives = [h['content'] for h in hard_negatives] + [e['content'] for e in easy_negatives]\n",
    "            need_more = target_neg_number - len(selected_negatives)\n",
    "            if need_more > 0 and un_relevant:\n",
    "                available = [n for n in un_relevant if n not in selected_negatives]\n",
    "                if available:\n",
    "                    selected_negatives += random.sample(available, min(need_more, len(available)))\n",
    "        # 情况2：负样本总数足够，优先组合难负和易分负样本\n",
    "        else:\n",
    "            if len(hard_negatives) >= 1:\n",
    "                selected_negatives.append(random.choice(hard_negatives)['content'])\n",
    "                remaining = target_neg_number - 1\n",
    "                if len(easy_negatives) >= remaining:\n",
    "                    selected_negatives += [e['content'] for e in random.sample(easy_negatives, remaining)]\n",
    "                else:\n",
    "                    selected_negatives += [h['content'] for h in random.sample(hard_negatives, remaining)]\n",
    "            else:\n",
    "                selected_negatives = [e['content'] for e in random.sample(easy_negatives, target_neg_number)]\n",
    "        if len(selected_negatives) < target_neg_number and un_relevant:\n",
    "            need_more = target_neg_number - len(selected_negatives)\n",
    "            available = [n for n in un_relevant if n not in selected_negatives]\n",
    "            if available:\n",
    "                selected_negatives += random.sample(available, min(need_more, len(available)))\n",
    "        process_data.append({'query': query, 'positive': pos, 'negative': selected_negatives})\n",
    "\n",
    "with open(f'train_data_with_neg_num_{target_neg_number}.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(process_data, f, ensure_ascii=False, indent=4)\n",
    "print(\"\\n难负样本构建完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af473caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = []\n",
    "for data in tqdm(eval_data):\n",
    "    query = data['query']\n",
    "    contents = []\n",
    "    content_private = data['content_private']\n",
    "    content_public = data['content_public']\n",
    "    for content in content_private:\n",
    "        content_text = content['content']\n",
    "        if not content_text:\n",
    "            continue\n",
    "        label = content['is_relevant']\n",
    "        contents.append({'content': content_text, 'label': label})\n",
    "    for content in content_public:\n",
    "        content_text = content['content']\n",
    "        if not content_text:\n",
    "            continue\n",
    "        label = content['is_relevant']\n",
    "        contents.append({'content': content_text, 'label': label})\n",
    "        \n",
    "    eval_dataset.append({'query': query, 'documents': contents})\n",
    "\n",
    "with open(f'eval_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(eval_dataset, f, ensure_ascii=False, indent=4)\n",
    "print(\"\\n测试样本构建完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwen3_emb\n",
    "class QwenEmbeddingRetrieval:\n",
    "    def __init__(self, model_path, task_description=None):\n",
    "        self.model_path = model_path\n",
    "        self.task_description = task_description or \"Given a web search query, retrieve relevant passages that answer the query\"\n",
    "        self.model = None\n",
    "        self.documents = []\n",
    "        self.document_embeddings = None\n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        self.model = LLM(model=self.model_path, task=\"embed\")\n",
    "\n",
    "    def get_detailed_instruct(self, query: str) -> str:\n",
    "        return f'Instruct: {self.task_description}\\nQuery:{query}'\n",
    "    \n",
    "    def fit(self, documents):\n",
    "        self.documents = documents\n",
    "        input_texts = documents\n",
    "        outputs = self.model.embed(input_texts)\n",
    "        self.document_embeddings = torch.tensor([o.outputs.embedding for o in outputs])\n",
    "        return self.document_embeddings\n",
    "    \n",
    "    def score(self, query, doc_index):\n",
    "        if doc_index >= len(self.documents) or self.document_embeddings is None:\n",
    "            return 0\n",
    "        query_embedding = self._get_query_embedding(query)\n",
    "        doc_embedding = self.document_embeddings[doc_index]\n",
    "        similarity = torch.dot(query_embedding, doc_embedding).item()\n",
    "        return similarity\n",
    "    \n",
    "    def _get_query_embedding(self, query):\n",
    "        instructed_query = self.get_detailed_instruct(query)\n",
    "        outputs = self.model.embed([instructed_query])\n",
    "        query_embedding = torch.tensor([o.outputs.embedding for o in outputs])[0]\n",
    "        return query_embedding\n",
    "    \n",
    "    def search(self, query, top_k=None):\n",
    "        if self.document_embeddings is None:\n",
    "            raise ValueError(\"请先调用fit方法处理文档\")\n",
    "        query_embedding = self._get_query_embedding(query)\n",
    "        scores = (query_embedding @ self.document_embeddings.T).tolist()\n",
    "        results = []\n",
    "        for i, score in enumerate(scores):\n",
    "            # results.append((i, score, self.documents[i]))\n",
    "            results.append((i, score))\n",
    "        # results.sort(key=lambda x: x[1], reverse=True)\n",
    "        # if top_k is not None:\n",
    "        #     return results[:top_k]\n",
    "        # else:\n",
    "        #     return results\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = \"/root/lanyun-fs/models/Qwen3-Embedding-0.6B\"\n",
    "qwen3_emb_retrieval = QwenEmbeddingRetrieval(model_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d18bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "scores = []\n",
    "for e_data in tqdm(eval_dataset):\n",
    "\n",
    "    query = e_data['query']\n",
    "    doc_contents = [doc[\"content\"] for doc in e_data['documents']]\n",
    "    doc_labels = [doc[\"label\"] for doc in e_data['documents']]\n",
    "    qwen3_emb_retrieval.fit(doc_contents)\n",
    "    results_qwen3_emb = qwen3_emb_retrieval.search(query)\n",
    "    score = [res[1] for res in results_qwen3_emb]\n",
    "    labels.extend(doc_labels)\n",
    "    scores.extend(score)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'doc_label': labels,     \n",
    "    'retrieval_result': scores\n",
    "})\n",
    "\n",
    "df.to_csv('eval_results.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca388c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientEmbeddingRetrieval:\n",
    "    def __init__(self, model, api_key, base_url, task_description=None):\n",
    "        self.task_description = task_description or \"Given a web search query, retrieve relevant passages that answer the query\"\n",
    "        self.documents = []\n",
    "        self.document_embeddings = None\n",
    "        self.model = model\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def get_detailed_instruct(self, query: str) -> str:\n",
    "        return f'Instruct: {self.task_description}\\nQuery:{query}'\n",
    "        \n",
    "    def fit(self, documents):\n",
    "        self.documents = documents\n",
    "        input_texts = documents\n",
    "        response = self.client.embeddings.create(input=input_texts,model=self.model)\n",
    "        self.document_embeddings = torch.tensor([res.embedding for res in response.data])\n",
    "        return self.document_embeddings\n",
    "\n",
    "    def score(self, query, doc_index):\n",
    "        if doc_index >= len(self.documents) or self.document_embeddings is None:\n",
    "            return 0\n",
    "        query_embedding = self._get_query_embedding(query)\n",
    "        doc_embedding = self.document_embeddings[doc_index]\n",
    "        similarity = torch.dot(query_embedding, doc_embedding).item()\n",
    "        return similarity\n",
    "    \n",
    "    def _get_query_embedding(self, query):\n",
    "        \n",
    "        instructed_query = self.get_detailed_instruct(query)\n",
    "        response = self.client.embeddings.create(input=[instructed_query],model=self.model)\n",
    "        query_embedding = torch.tensor([res.embedding for res in response.data])[0]\n",
    "        return query_embedding\n",
    "    \n",
    "    def search(self, query, top_k=None):\n",
    "        if self.document_embeddings is None:\n",
    "            raise ValueError(\"请先调用fit方法处理文档\")\n",
    "        query_embedding = self._get_query_embedding(query)\n",
    "        scores = (query_embedding @ self.document_embeddings.T).tolist()\n",
    "        results = []\n",
    "        for i, score in enumerate(scores):\n",
    "            # results.append((i, score, self.documents[i]))\n",
    "            results.append((i, score))\n",
    "        # results.sort(key=lambda x: x[1], reverse=True)\n",
    "        # if top_k is not None:\n",
    "        #     return results[:top_k]\n",
    "        # else:\n",
    "        #     return results\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de071360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "teacher_retrieval = ClientEmbeddingRetrieval(model=\"Qwen/Qwen3-Embedding-8B\", \n",
    "                                             api_key=\"***\", \n",
    "                                             base_url=\"***\")\n",
    "\n",
    "labels = []\n",
    "scores_teachers = []\n",
    "scores_students = []\n",
    "for e_data in tqdm(eval_dataset):\n",
    "\n",
    "    query = e_data['query']\n",
    "    doc_contents = [doc[\"content\"] for doc in e_data['documents']]\n",
    "    doc_labels = [doc[\"label\"] for doc in e_data['documents']]\n",
    "    teacher_retrieval.fit(doc_contents)\n",
    "    teacher_emb = teacher_retrieval.search(query)\n",
    "    score_teacher = [res[1] for res in teacher_emb]\n",
    "    scores_teachers.extend(score_teacher)\n",
    "\n",
    "    qwen3_emb_retrieval.fit(doc_contents)\n",
    "    results_qwen3_emb = qwen3_emb_retrieval.search(query)\n",
    "    scores_student = [res[1] for res in results_qwen3_emb]\n",
    "    scores_students.extend(scores_student)\n",
    "    labels.extend(doc_labels)\n",
    "    time.sleep(3)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'doc_label': labels,     \n",
    "    'scores_teachers': scores_teachers,\n",
    "    'scores_students': scores_students\n",
    "})\n",
    "\n",
    "df.to_csv('eval_results.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef614570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_label'] = df['doc_label'].astype(int)\n",
    "threshould = 0.5\n",
    "df['pred_teachers'] = (df['scores_teachers'] > threshould).astype(int)\n",
    "df['pred_students'] = (df['scores_students'] > threshould).astype(int)\n",
    "\n",
    "f1_teachers = f1_score(df['true_label'], df['pred_teachers'])\n",
    "f1_students = f1_score(df['true_label'], df['pred_students'])\n",
    "\n",
    "print(f\"教师预测的F1分数：{f1_teachers:.4f}\")\n",
    "print(f\"学生预测的F1分数：{f1_students:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fa8c7-960a-4ec1-bcda-531a8470c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class MultiNegTripletDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512, num_negatives_per_sample=3):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.num_negatives_per_sample = num_negatives_per_sample\n",
    "\n",
    "        self.filtered_data = []\n",
    "        for item in self.data:\n",
    "            if len(item['negative']) >= self.num_negatives_per_sample:\n",
    "                selected_negatives = random.sample(item['negative'], self.num_negatives_per_sample)\n",
    "                self.filtered_data.append({\n",
    "                    'query': item['query'],\n",
    "                    'positive': item['positive'],\n",
    "                    'negative': selected_negatives\n",
    "                })\n",
    "        print(f\"过滤后保留 {len(self.filtered_data)}/{len(self.data)} 条数据（确保每个样本有足够的负样本）\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.filtered_data[idx]\n",
    "        query = item['query']\n",
    "        positive = item['positive']\n",
    "        negatives = item['negative']\n",
    "        \n",
    "        query_encoding = self.tokenizer(\n",
    "            query,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        positive_encoding = self.tokenizer(\n",
    "            positive,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        negative_encodings = []\n",
    "        for neg in negatives:\n",
    "            neg_encoding = self.tokenizer(\n",
    "                neg,\n",
    "                max_length=self.max_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            negative_encodings.append({\n",
    "                'input_ids': neg_encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': neg_encoding['attention_mask'].squeeze(0)\n",
    "            })\n",
    "        \n",
    "        result = {\n",
    "            'query_input_ids': query_encoding['input_ids'].squeeze(0),\n",
    "            'query_attention_mask': query_encoding['attention_mask'].squeeze(0),\n",
    "            'positive_input_ids': positive_encoding['input_ids'].squeeze(0),\n",
    "            'positive_attention_mask': positive_encoding['attention_mask'].squeeze(0),\n",
    "        }\n",
    "        \n",
    "        for i, neg_encoding in enumerate(negative_encodings):\n",
    "            result[f'negative_{i}_input_ids'] = neg_encoding['input_ids']\n",
    "            result[f'negative_{i}_attention_mask'] = neg_encoding['attention_mask']\n",
    "        return result\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def prepare_model(model_path, use_lora=True, use_gradient_checkpointing=True):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_path,\n",
    "        device_map='auto',\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    if use_gradient_checkpointing:\n",
    "        model.gradient_checkpointing_enable()\n",
    "        print(\"已启用梯度检查点\")\n",
    "\n",
    "    def qwen_pooling(model_output, attention_mask):\n",
    "        return model_output.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    if use_lora:\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "        lora_config = LoraConfig(\n",
    "            r=16,\n",
    "            lora_alpha=32,\n",
    "            target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"FEATURE_EXTRACTION\",\n",
    "        )\n",
    "        \n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()\n",
    "    \n",
    "    return model, tokenizer, qwen_pooling\n",
    "\n",
    "class MultiNegTripletLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0, temperature=0.05):\n",
    "        super(MultiNegTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, query_emb, positive_emb, negative_embs):\n",
    "        query_emb = torch.nn.functional.normalize(query_emb, p=2, dim=1)\n",
    "        positive_emb = torch.nn.functional.normalize(positive_emb, p=2, dim=1)\n",
    "        pos_sim = torch.sum(query_emb * positive_emb, dim=1) / self.temperature\n",
    "        neg_sims = []\n",
    "        for neg_emb in negative_embs:\n",
    "            neg_emb = torch.nn.functional.normalize(neg_emb, p=2, dim=1)\n",
    "            neg_sim = torch.sum(query_emb * neg_emb, dim=1) / self.temperature\n",
    "            neg_sims.append(neg_sim.unsqueeze(1))\n",
    "        all_neg_sims = torch.cat(neg_sims, dim=1)\n",
    "        labels = torch.zeros(query_emb.size(0), dtype=torch.long).to(query_emb.device)\n",
    "        logits = torch.cat([pos_sim.unsqueeze(1), all_neg_sims], dim=1)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return loss\n",
    "\n",
    "class MultiNegDataCollator:\n",
    "    def __init__(self, num_negatives_per_sample=3):\n",
    "        self.num_negatives_per_sample = num_negatives_per_sample\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        result = {}\n",
    "        for key in batch[0].keys():\n",
    "            if key.startswith('query_') or key.startswith('positive_'):\n",
    "                result[key] = torch.stack([item[key] for item in batch])\n",
    "            elif key.startswith('negative_'):\n",
    "                result[key] = torch.stack([item[key] for item in batch])\n",
    "        return result\n",
    "\n",
    "class MultiNegEmbeddingTrainer(Trainer):\n",
    "    def __init__(self, *args, mean_pooling_fn=None, num_negatives_per_sample=3, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mean_pooling_fn = mean_pooling_fn\n",
    "        self.loss_fn = MultiNegTripletLoss()\n",
    "        self.num_negatives_per_sample = num_negatives_per_sample\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        model.train()\n",
    "        query_outputs = model(\n",
    "            input_ids=inputs['query_input_ids'],\n",
    "            attention_mask=inputs['query_attention_mask'],\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        positive_outputs = model(\n",
    "            input_ids=inputs['positive_input_ids'],\n",
    "            attention_mask=inputs['positive_attention_mask'],\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        query_emb = self.mean_pooling_fn(query_outputs, inputs['query_attention_mask'])\n",
    "        positive_emb = self.mean_pooling_fn(positive_outputs, inputs['positive_attention_mask'])\n",
    "        negative_embs = []\n",
    "        for i in range(self.num_negatives_per_sample):\n",
    "            neg_outputs = model(\n",
    "                input_ids=inputs[f'negative_{i}_input_ids'],\n",
    "                attention_mask=inputs[f'negative_{i}_attention_mask'],\n",
    "                output_hidden_states=True\n",
    "            )\n",
    "            neg_emb = self.mean_pooling_fn(neg_outputs, inputs[f'negative_{i}_attention_mask'])\n",
    "            negative_embs.append(neg_emb)\n",
    "        loss = self.loss_fn(query_emb, positive_emb, negative_embs)\n",
    "        return (loss, (query_emb, positive_emb, negative_embs)) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only=False, ignore_keys=None):\n",
    "        with torch.no_grad():\n",
    "            loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
    "        return (loss, None, None)\n",
    "\n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        self.optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.args.learning_rate,\n",
    "            betas=(self.args.adam_beta1, self.args.adam_beta2),\n",
    "            eps=self.args.adam_epsilon,\n",
    "        )\n",
    "        self.lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=self.args.warmup_steps,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63680811-2d44-4aa0-9271-a19e8df95287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model_path = \"/root/lanyun-fs/models/Qwen3-Embedding-0.6B\"\n",
    "    data_path = 'train_data_with_neg_num_3.json'\n",
    "    output_dir = './qwen3_embedding_model_multi_neg_lora'\n",
    "    batch_size = 16\n",
    "    num_epochs = 3\n",
    "    learning_rate = 1e-4\n",
    "    num_negatives_per_sample = 3\n",
    "    \n",
    "    print(\"加载数据...\")\n",
    "    data = load_data(data_path)\n",
    "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"准备模型...\")\n",
    "    model, tokenizer, pooling_fn = prepare_model(\n",
    "        model_path, \n",
    "        use_lora=True, \n",
    "        use_gradient_checkpointing=True\n",
    "    )\n",
    "\n",
    "    print(\"创建数据集...\")\n",
    "    train_dataset = MultiNegTripletDataset(\n",
    "        train_data, \n",
    "        tokenizer, \n",
    "        max_len=1024,\n",
    "        num_negatives_per_sample=num_negatives_per_sample\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultiNegTripletDataset(\n",
    "        val_data, \n",
    "        tokenizer, \n",
    "        max_len=1024,\n",
    "        num_negatives_per_sample=num_negatives_per_sample\n",
    "    )\n",
    "\n",
    "    if len(train_dataset) == 0:\n",
    "        raise ValueError(\"训练数据集为空，请检查数据过滤条件\")\n",
    "    if len(val_dataset) == 0:\n",
    "        raise ValueError(\"验证数据集为空，请检查数据过滤条件\")\n",
    "\n",
    "    data_collator = MultiNegDataCollator(num_negatives_per_sample=num_negatives_per_sample)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=int(0.1 * num_epochs * len(train_dataset) / batch_size),\n",
    "        learning_rate=learning_rate,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=2,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=50,\n",
    "        save_strategy='steps',\n",
    "        save_steps=200,\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        fp16=True,\n",
    "        gradient_accumulation_steps=2,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        ddp_find_unused_parameters=False,\n",
    "        weight_decay=0.01,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.999,\n",
    "        adam_epsilon=1e-8,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        disable_tqdm=False,\n",
    "        prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "    print(\"创建训练器...\")\n",
    "    trainer = MultiNegEmbeddingTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        mean_pooling_fn=pooling_fn,\n",
    "        num_negatives_per_sample=num_negatives_per_sample\n",
    "    )\n",
    "\n",
    "    print(\"开始训练...\")\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"保存模型...\")\n",
    "    model.save_pretrained(f\"{output_dir}/final_model\")\n",
    "    tokenizer.save_pretrained(f\"{output_dir}/final_tokenizer\")\n",
    "    print(f\"模型已保存至 {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f50ab8-bac8-49f7-a33e-10573bf704d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95401917-24a2-4c1b-befb-aaa737832876",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"/root/lanyun-fs/models/Qwen3-Embedding-0.6B\"\n",
    "model = AutoModel.from_pretrained(base_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "lora_path = './qwen3_embedding_model_multi_neg_lora/final_model'\n",
    "model = PeftModel.from_pretrained(model, lora_path)\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"merged_model/Qwen3-Embedding-0.6B\")\n",
    "tokenizer.save_pretrained(\"merged_model/Qwen3-Embedding-0.6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3bb60-74ec-4b14-8e4e-7659be6f4df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('eval_data.json', 'r', encoding='utf-8') as f:\n",
    "    eval_dataset = json.load(f)\n",
    "    \n",
    "model_emb_lora = \"./merged_model/Qwen3-Embedding-0.6B\"\n",
    "qwen3_emb_lora_retrieval = QwenEmbeddingRetrieval(model_emb_lora)\n",
    "\n",
    "model_emb = \"/root/lanyun-fs/models/Qwen3-Embedding-0.6B\"\n",
    "qwen3_emb_retrieval = QwenEmbeddingRetrieval(model_emb)\n",
    "\n",
    "scores_lora = []\n",
    "scores_base = []\n",
    "labels = []\n",
    "for e_data in tqdm(eval_dataset):\n",
    "\n",
    "    query = e_data['query']\n",
    "    doc_contents = [doc[\"content\"] for doc in e_data['documents']]\n",
    "    doc_labels = [doc[\"label\"] for doc in e_data['documents']]\n",
    "\n",
    "    qwen3_emb_lora_retrieval.fit(doc_contents)\n",
    "    results_qwen3_emb_lora = qwen3_emb_lora_retrieval.search(query)\n",
    "    score_lora = [res[1] for res in results_qwen3_emb_lora]\n",
    "\n",
    "    qwen3_emb_retrieval.fit(doc_contents)\n",
    "    results_qwen3_emb = qwen3_emb_retrieval.search(query)\n",
    "    score = [res[1] for res in results_qwen3_emb]\n",
    "    \n",
    "    scores_lora.extend(score_lora)\n",
    "    scores_base.extend(score)    \n",
    "    labels.extend(doc_labels)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'doc_label': labels,     \n",
    "    'scores_lora': scores_lora,\n",
    "    'scores_base': scores_base,   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e121d3-5cca-4323-b541-27ce888f040f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['true_label'] = df['doc_label'].astype(int)\n",
    "threshould = 0.7\n",
    "\n",
    "df['pred_lora'] = (df['scores_lora'] > threshould).astype(int)\n",
    "df['pred_base'] = (df['scores_base'] > threshould).astype(int)\n",
    "\n",
    "f1_lora = f1_score(df['true_label'], df['pred_lora'])\n",
    "f1_base = f1_score(df['true_label'], df['pred_base'])\n",
    "\n",
    "print(f\"原始模型预测的F1分数：{f1_base:.4f}\")\n",
    "print(f\"lora微调后的模型预测的F1分数：{f1_lora:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee33f5e-900b-4fa8-a514-44026cf53d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "threshould = 0.4\n",
    "原始模型预测的F1分数：0.6210\n",
    "lora微调后的模型预测的F1分数：0.5879\n",
    "\n",
    "threshould = 0.5\n",
    "原始模型预测的F1分数：0.6480\n",
    "lora微调后的模型预测的F1分数：0.6150\n",
    "\n",
    "threshould = 0.6\n",
    "原始模型预测的F1分数：0.5950\n",
    "lora微调后的模型预测的F1分数：0.6516\n",
    "\n",
    "threshould = 0.7\n",
    "原始模型预测的F1分数：0.3748\n",
    "lora微调后的模型预测的F1分数：0.5627\n",
    "'''\n",
    "\n",
    "'''\n",
    "模型预测结果与阈值强相关\n",
    "LoRA 微调改变了模型的预测分布，使其在高阈值下表现更优，可能更适合对 “预测可靠性” 要求高的场景\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
